# 提示适应作为生成式AI系统中的动态补充

**作者**：
- Eaman Jahani (马里兰大学)
- Benjamin S. Manning (MIT)
- Joe Zhang (斯坦福大学)
- Hong-Yi TuYe (MIT)
- Mohammed Alsobay (MIT)
- Christos Nicolaides (塞浦路斯大学)
- Siddharth Suri† (微软研究院)
- David Holtz† (加州大学伯克利分校)

**日期**：2025年4月22日

**arXiv**：2407.14333v5 [cs.HC] 2025年4月18日

## 摘要

随着生成式AI系统的快速发展，一个关键问题浮现：用户如何跟上步伐——如果他们跟不上会发生什么。基于动态能力和IT补充理论，我们研究了**提示适应**——用户根据不断发展的模型行为对其输入进行的调整——作为一种机制，帮助确定技术进步是否转化为实际经济价值。

在一项预注册的在线实验中，1,893名参与者提交了超过18,000个提示，生成了超过300,000张图像，用户尝试在10次尝试中使用三种随机分配的模型之一来复制目标图像：DALL-E 2、DALL-E 3或带有自动提示重写的DALL-E 3。我们发现，使用DALL-E 3的用户比使用DALL-E 2的用户实现了更高的图像相似度——但只有大约一半的收益（51%）来自模型本身。另一半（49%）来自用户根据模型能力调整其提示。

这种适应在整个技能分布中出现，由试错驱动，并且无法通过自动提示重写复制，后者消除了与DALL-E 3相关的58%的性能改进。我们的研究结果将提示适应定位为生成式AI的动态补充——并表明如果没有它，模型进步创造的经济价值可能有很大一部分无法实现。

## 1 引言

生成式AI正在融入整个经济的工作实践中，在软件开发、写作和材料发现等多样化任务中产生显著的生产力收益。最近的研究指出了更大的潜力，展示了在自动化核心科学过程方面的进展，包括化学研究和证明数学定理等复杂任务。

与许多其他通用技术一样，生成式AI的有效性不仅取决于技术本身，还取决于用户制作产生高质量结果的输入的能力。为了与生成式AI系统交互，用户提供书面指令——通常称为提示——指导模型的行为。这些提示可以从简单的命令到为特定输出量身定制的高度详细规范。

提示已成为活跃研究和实践的领域。学者们开发了提示工程技术分类法，记录了提示构建中的重复模式，并检查了开发人员如何将提示嵌入软件系统。其他研究探索了特定应用的提示策略，包括图像生成和临床文档。

尽管存在这种共识，但提示作为一种动态实践仍然研究不足。许多提示库和教程将有效提示呈现为可重用工件。但适用于一个模型版本的提示可能在下一个版本中表现不佳或完全失效。虽然最近的研究越来越多地将提示视为自适应过程，但关于这些策略如何演变——无论是用户为单一模型优化提示还是他们适应模型更新——以及这些变化最终如何影响性能的经验证据仍然有限。

## 2 概念框架

随着生成式AI系统的发展，用户为改进模型调整提示的能力可能成为实现性能增益的重要来源。我们开发了一个风格化的概念框架，以形式化整体输出质量如何取决于模型容量和用户在提示写作中的技能和努力。

### 2.1 符号和问题设置

令θ ∈ (0, 1]表示模型将提示转换为高保真输出的容量（例如，它捕获请求细节的准确程度）。令s ∈ (0, 1]表示用户在提示工程中的基线技能，令x ≥ 0表示用户在编写和优化提示上付出的努力。

质量函数定义为：
Q(θ, s, x) = 1 - e^(-θ s x)

用户的效用为：
U(θ, s, x) = Q(θ, s, x) - k x

### 2.2 分解为模型和提示效应

当模型容量θ增加时，最优提示努力x*也增加，这意味着更有能力的模型不仅为固定提示提供更好的输出，还鼓励用户投入更多努力来编写提示。

总质量改进可以分解为：
ΔQ = [Q(θ₂, s, x*(θ₁, s)) - Q(θ₁, s, x*(θ₁, s))] + [Q(θ₂, s, x*(θ₂, s)) - Q(θ₂, s, x*(θ₁, s))]

第一项隔离了仅升级模型的收益（将用户的提示策略固定在旧的优化水平），而第二项表示来自提示适应的任何额外收益。

## 3 实验设计和方法

为了实证检验用户是否确实根据模型改进调整其提示——以及这种适应对整体性能的贡献程度——我们在2023年12月12日至19日期间在Prolific上进行了一项预注册的在线实验，有2,059名参与者。

### 3.1 实验设置

每个参与者被随机盲目分配到三种模型条件之一：
- DALL-E 2
- DALL-E 3（字面意思）
- DALL-E 3（修订版）

这些模型不仅在技术能力上不同，而且在是否应用基于大型语言模型的隐藏用户提示修改上不同。

### 3.2 结果定义和随机生成

我们实验中的主要结果是每个参与者生成的图像与分配的目标图像之间的相似度，使用CLIP嵌入的余弦相似度测量。

### 3.3 重放分析用于分离模型和提示效应

我们实验的一个核心目标是区分图像复制中的性能改进有多少来自使用更有能力的模型，有多少来自用户调整其提示。

## 4 结果

### 4.1 模型升级的整体影响

分配到DALL-E 3的参与者比分配到DALL-E 2的参与者产生显著更忠实的复制品。重要的是，大约一半的这种改进来自参与者调整其提示以利用新模型的能力——在DALL-E 3上重放旧的DALL-E 2提示仅产生大约一半的总改进。

### 4.2 重放分析和效应分解

我们的重放分析显示，提示适应占整体性能改进的近一半，其余归因于模型的增强渲染能力。

### 4.3 技能异质性

模型改进减少了高技能和低技能用户之间的整体差距。模型效应主要惠及表现较差的用户，而提示适应的收益在整个技能分布中没有显著变化。

### 4.4 提示修订

通过GPT-4重写自动提示适应系统无法替代人类驱动的适应。平均而言，自动提示修订将DALL-E 3的收益减少了58%。

## 5 讨论和结论

我们的研究结果通过强调提示适应作为与模型改进共同演化的动态补充的作用，为人类-AI协作和技术经济学文献做出了贡献。

这种共同演化模式并非AI独有。它呼应了早期通用技术中观察到的动态，其中技术改进通常产生适度的回报，直到补充技能和实践发展到匹配。然而，生成式AI的进步速度带来了独特的挑战：适应窗口要短得多。

这一发现扩展了IT驱动的动态能力和采用后IT使用的研究，强调了价值如何通过用户实验和学习随时间出现。我们观察到的提示适应并非基于正式培训或专业技能。我们研究中的参与者——没有一个是专家提示工程师——在单个会话中通过试错提高了性能。

同时，这种可访问性引入了风险。为特定模型版本过度优化可能会降低用户随着系统发展而适应的能力。

最后，我们的结果警告不要使用与用户意图不一致的自动提示系统。在我们的实验中，DALL-E 3的自动提示重写——旨在增强可用性——将实现的性能增益减少了58%。

## 局限性和未来研究方向

本研究有几个局限性：
1. 我们的焦点仅限于单一过渡（从DALL-E 2到DALL-E 3）和一种类型的生成式AI（文本到图像生成）
2. 我们在受控环境中观察短期适应行为
3. 虽然我们的重放分析隔离了提示适应的效应，但我们没有确定哪些特定类型的提示修改对性能有因果效应

有前途的研究方向包括纵向检查提示适应、组织级提示补充、界面设计，以及组织如何平衡标准化与提示工作流程中的适应性。

## 参考文献

[完整的参考文献列表]

---

*注：本文档是原始英文论文的中文翻译和结构化版本，保留了核心内容和研究结果。*