package examples

import (
	"context"
	"fmt"

	"github.com/wordflowlab/agentsdk/pkg/backends"
	"github.com/wordflowlab/agentsdk/pkg/middleware"
	"github.com/wordflowlab/agentsdk/pkg/types"
)

// Phase4IntegrationExample å±•ç¤ºå¦‚ä½•é›†æˆ SummarizationMiddleware å’Œ AgentMemoryMiddleware
func Phase4IntegrationExample() error {
	ctx := context.Background()

	// 1. åˆ›å»ºåç«¯å­˜å‚¨
	// ä½¿ç”¨ CompositeBackend æ”¯æŒå¤šè·¯å¾„è·¯ç”±
	composite := backends.NewCompositeBackend([]backends.Route{
		{Prefix: "/memories/", Backend: createStoreBackend()},
		{Prefix: "/", Backend: createFilesystemBackend()},
	})

	// 2. åˆ›å»ºè‡ªå®šä¹‰ Summarizer (ä½¿ç”¨çœŸå® LLM)
	customSummarizer := func(ctx context.Context, messages []types.Message) (string, error) {
		// è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„ LLM API ç”Ÿæˆæ€»ç»“
		// ç¤ºä¾‹ä½¿ç”¨ Provider æ¥å£
		return generateSummaryWithLLM(ctx, messages)
	}

	// 3. åˆ›å»º SummarizationMiddleware
	summarizationMW, err := middleware.NewSummarizationMiddleware(&middleware.SummarizationMiddlewareConfig{
		Summarizer:             customSummarizer,
		MaxTokensBeforeSummary: 170000, // Claude 3.5 Sonnet çš„ 200k ä¸Šä¸‹æ–‡çš„ 85%
		MessagesToKeep:         6,      // ä¿ç•™æœ€è¿‘ 3 è½®å¯¹è¯
		SummaryPrefix:          "## Previous conversation summary:",
	})
	if err != nil {
		return fmt.Errorf("failed to create summarization middleware: %w", err)
	}

	// 4. åˆ›å»º AgentMemoryMiddleware
	memoryMW, err := middleware.NewAgentMemoryMiddleware(&middleware.AgentMemoryMiddlewareConfig{
		Backend:    composite,
		MemoryPath: "/memories/",
		// ä½¿ç”¨é»˜è®¤æ¨¡æ¿: <agent_memory>...</agent_memory>
	})
	if err != nil {
		return fmt.Errorf("failed to create agent memory middleware: %w", err)
	}

	// 5. æ„å»ºä¸­é—´ä»¶æ ˆ
	middlewares := []middleware.Middleware{
		memoryMW,        // ä¼˜å…ˆçº§ 5: æœ€æ—©æ‰§è¡Œ,æ³¨å…¥è®°å¿†
		summarizationMW, // ä¼˜å…ˆçº§ 40: åœ¨è°ƒç”¨æ¨¡å‹å‰æ£€æŸ¥å¹¶æ€»ç»“
		// ... å…¶ä»–ä¸­é—´ä»¶
	}

	// 6. åˆ›å»º Agent å¹¶ä½¿ç”¨ä¸­é—´ä»¶
	fmt.Printf("Created agent with %d middlewares\n", len(middlewares))
	fmt.Printf("- SummarizationMiddleware: max_tokens=%d, keep_messages=%d\n",
		170000, 6)
	fmt.Printf("- AgentMemoryMiddleware: memory_path=%s\n", "/memories/")

	return nil
}

// generateSummaryWithLLM ä½¿ç”¨ LLM ç”Ÿæˆå¯¹è¯æ€»ç»“
func generateSummaryWithLLM(ctx context.Context, messages []types.Message) (string, error) {
	// è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å®ç°
	// å®é™…åº”ç”¨ä¸­åº”è¯¥:
	// 1. ä½¿ç”¨ Provider æ¥å£è°ƒç”¨ LLM
	// 2. ä½¿ç”¨ä¸“é—¨çš„æ€»ç»“æç¤ºè¯
	// 3. è®¾ç½®è¾ƒä½çš„ temperature (å¦‚ 0.3)

	// æ„å»ºæ€»ç»“è¯·æ±‚
	summaryPrompt := `Please provide a concise summary of the following conversation, capturing:
1. Main topics discussed
2. Important decisions or conclusions
3. Action items or next steps
4. Relevant technical details or constraints

Keep the summary focused and informative, around 200-300 words.`

	// ç»„è£…æ¶ˆæ¯
	summaryMessages := []types.Message{
		{
			Role: types.MessageRoleSystem,
			Content: []types.ContentBlock{
				&types.TextBlock{Text: summaryPrompt},
			},
		},
	}
	summaryMessages = append(summaryMessages, messages...)

	// TODO: è°ƒç”¨ Provider çš„ Stream æ–¹æ³•
	// resp, err := provider.Stream(ctx, summaryMessages, &provider.StreamOptions{
	//     Temperature: 0.3,
	//     MaxTokens:   500,
	// })

	// ç¤ºä¾‹è¿”å›
	return "Summary of conversation: [Topics discussed, decisions made, next steps...]", nil
}

// createStoreBackend åˆ›å»º Store Backend (æŒä¹…åŒ–å­˜å‚¨)
func createStoreBackend() backends.BackendProtocol {
	// å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„ Store Backend
	// è¿™é‡Œè¿”å› nil ä»…ç”¨äºç¤ºä¾‹
	return nil
}

// createFilesystemBackend åˆ›å»º Filesystem Backend
func createFilesystemBackend() backends.BackendProtocol {
	// å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„ Filesystem Backend
	// è¿™é‡Œè¿”å› nil ä»…ç”¨äºç¤ºä¾‹
	return nil
}

// AgentMemoryExample å±•ç¤ºå¦‚ä½•ç®¡ç† Agent è®°å¿†
func AgentMemoryExample() {
	// agent.md æ–‡ä»¶ç¤ºä¾‹å†…å®¹:
	agentMemoryExample := `# Agent Personality

You are Claude, a helpful AI coding assistant created by Anthropic.

## Core Principles

1. **Code Quality First**: Always write clean, well-documented code
2. **Test-Driven**: Write tests before implementing features
3. **Security Conscious**: Check for common vulnerabilities (SQL injection, XSS, etc.)

## User Preferences

- **Language**: Prefers Go over Python for backend services
- **Testing**: Uses table-driven tests in Go
- **Documentation**: Likes detailed inline comments
- **Code Style**: Follows official Go style guide

## Project Context

- Working on AgentSDK, a Go-based agent framework
- Recently implemented Phase 4 features (Summarization + Memory)
- Focus on production-ready, well-tested code

## Learning from Feedback

- User prefers progressive enhancement over big-bang changes
- User values incremental commits with clear messages
- User wants all tests to pass before committing`

	fmt.Println("=== Agent Memory Example ===")
	fmt.Println("\nCreate /agent.md with the following content:")
	fmt.Println(agentMemoryExample)
	fmt.Println("\nThe AgentMemoryMiddleware will:")
	fmt.Println("1. Load this file on agent start")
	fmt.Println("2. Inject it into every system prompt")
	fmt.Println("3. Add usage guidelines for long-term memory")
}

// AdvancedSummarizationExample å±•ç¤ºé«˜çº§æ€»ç»“ç­–ç•¥
func AdvancedSummarizationExample() {
	fmt.Println("=== Advanced Summarization Strategies ===")

	fmt.Println("\n1. Dynamic Threshold Based on Task Complexity:")
	fmt.Println("   - Simple tasks: 100k tokens")
	fmt.Println("   - Complex tasks: 150k tokens")
	fmt.Println("   - Code review: 180k tokens (need more context)")

	fmt.Println("\n2. Smart Message Retention:")
	fmt.Println("   - Keep recent 6 messages by default")
	fmt.Println("   - Keep more if containing important context:")
	fmt.Println("     * Error messages and stack traces")
	fmt.Println("     * User requirements or specifications")
	fmt.Println("     * Critical decisions")

	fmt.Println("\n3. Multi-Stage Summarization:")
	fmt.Println("   - Stage 1: Summarize every 50k tokens")
	fmt.Println("   - Stage 2: Re-summarize summaries at 150k tokens")
	fmt.Println("   - Keeps context compressed while preserving key info")

	fmt.Println("\n4. Custom Token Counting:")
	fmt.Println("   - Use model's official tokenizer for accuracy")
	fmt.Println("   - Account for tool definitions in token count")
	fmt.Println("   - Include system prompt in calculation")
}

// MonitoringExample å±•ç¤ºå¦‚ä½•ç›‘æ§ä¸­é—´ä»¶æ€§èƒ½
func MonitoringExample(summarizationMW *middleware.SummarizationMiddleware) {
	fmt.Println("=== Monitoring Middleware Performance ===")

	// è·å–é…ç½®
	config := summarizationMW.GetConfig()
	fmt.Printf("\nConfiguration:\n")
	fmt.Printf("  Max Tokens: %v\n", config["max_tokens_before_summary"])
	fmt.Printf("  Messages to Keep: %v\n", config["messages_to_keep"])
	fmt.Printf("  Summary Prefix: %v\n", config["summary_prefix"])

	// è·å–ç»Ÿè®¡ä¿¡æ¯
	count := summarizationMW.GetSummarizationCount()
	fmt.Printf("\nStatistics:\n")
	fmt.Printf("  Total Summarizations: %d\n", count)

	// å¦‚æœæ€»ç»“æ¬¡æ•°è¿‡å¤š,å¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼
	if count > 10 {
		fmt.Println("\nâš ï¸  Warning: High summarization count detected")
		fmt.Println("   Consider increasing max_tokens_before_summary")
		fmt.Println("   or reducing messages_to_keep")
	}
}

// BestPractices æœ€ä½³å®è·µæŒ‡å—
func BestPractices() {
	fmt.Println("=== Phase 4 Middleware Best Practices ===")

	fmt.Println("\nğŸ“‹ SummarizationMiddleware:")
	fmt.Println("  1. Use real LLM for summarization in production")
	fmt.Println("  2. Set max_tokens to 85% of model's context window")
	fmt.Println("  3. Monitor summarization count to tune parameters")
	fmt.Println("  4. Consider using cheaper models for summarization")
	fmt.Println("  5. Keep summaries concise (200-300 words)")

	fmt.Println("\nğŸ§  AgentMemoryMiddleware:")
	fmt.Println("  1. Keep agent.md focused and well-structured")
	fmt.Println("  2. Update regularly based on user feedback")
	fmt.Println("  3. Version control agent.md with git")
	fmt.Println("  4. Use CompositeBackend for flexible storage")
	fmt.Println("  5. Test agent behavior after updating memory")

	fmt.Println("\nğŸ”§ Integration:")
	fmt.Println("  1. Place AgentMemoryMiddleware early (low priority number)")
	fmt.Println("  2. Place SummarizationMiddleware before model call")
	fmt.Println("  3. Test with long conversations to verify behavior")
	fmt.Println("  4. Monitor token usage and adjust thresholds")
	fmt.Println("  5. Implement graceful degradation on errors")

	fmt.Println("\nğŸ¯ Production Checklist:")
	fmt.Println("  [ ] Custom summarizer implemented with real LLM")
	fmt.Println("  [ ] agent.md created and tested")
	fmt.Println("  [ ] Token thresholds tuned for your model")
	fmt.Println("  [ ] Monitoring and alerting set up")
	fmt.Println("  [ ] Error handling tested (LLM failure, file not found)")
	fmt.Println("  [ ] Performance benchmarked under load")
}
