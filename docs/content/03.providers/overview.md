# Providers æ€»è§ˆ

AgentSDK æ”¯æŒ 10+ ä¸ªä¸»æµ AI Providerï¼Œè¦†ç›–å›½é™…å’Œä¸­å›½å¸‚åœºã€‚

## æ”¯æŒçš„ Providers

### ğŸŒ å›½é™…ä¸»æµ

| Provider | ç‰¹ç‚¹ | é…ç½®åç§° | æ–‡æ¡£ |
|----------|------|---------|------|
| **OpenAI** | æœ€æµè¡Œï¼ŒGPT-4/o1/o3 | `openai` | [è¯¦ç»†æ–‡æ¡£](./openai.md) |
| **Anthropic** | Claude ç³»åˆ— | `anthropic` | [è¯¦ç»†æ–‡æ¡£](./anthropic.md) |
| **Gemini** | è¶…é•¿ä¸Šä¸‹æ–‡ 1Mï¼Œè§†é¢‘ç†è§£ | `gemini`, `google` | [è¯¦ç»†æ–‡æ¡£](./gemini.md) |
| **Groq** | è¶…å¿«æ¨ç†é€Ÿåº¦ | `groq` | [è¯¦ç»†æ–‡æ¡£](./groq.md) |
| **OpenRouter** | èšåˆå¹³å°ï¼Œæ•°ç™¾æ¨¡å‹ | `openrouter` | [è¯¦ç»†æ–‡æ¡£](./openrouter.md) |
| **Mistral** | æ¬§æ´²ä¸»æµï¼Œå¼€æºå‹å¥½ | `mistral` | [è¯¦ç»†æ–‡æ¡£](./mistral.md) |
| **Ollama** | æœ¬åœ°éƒ¨ç½²é¦–é€‰ | `ollama` | [è¯¦ç»†æ–‡æ¡£](./ollama.md) |

### ğŸ‡¨ğŸ‡³ ä¸­å›½å¸‚åœº

| Provider | ç‰¹ç‚¹ | é…ç½®åç§° | æ–‡æ¡£ |
|----------|------|---------|------|
| **DeepSeek** | R1 æ¨ç†æ¨¡å‹ | `deepseek` | [è¯¦ç»†æ–‡æ¡£](./deepseek.md) |
| **æ™ºè°± GLM** | ChatGLM ç³»åˆ— | `glm`, `zhipu` | [è¯¦ç»†æ–‡æ¡£](./glm.md) |
| **è±†åŒ… Doubao** | å­—èŠ‚è·³åŠ¨ä¼ä¸šçº§ | `doubao`, `bytedance` | [è¯¦ç»†æ–‡æ¡£](./doubao.md) |
| **æœˆä¹‹æš—é¢ Kimi** | é•¿ä¸Šä¸‹æ–‡ 200K | `moonshot`, `kimi` | [è¯¦ç»†æ–‡æ¡£](./moonshot.md) |

## å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨

```go
import (
	"github.com/wordflowlab/agentsdk/pkg/provider"
	"github.com/wordflowlab/agentsdk/pkg/types"
)

// åˆ›å»ºé…ç½®
config := &types.ModelConfig{
	Provider: "openai",    // é€‰æ‹© Provider
	Model:    "gpt-4o",    // é€‰æ‹©æ¨¡å‹
	APIKey:   "your-key",  // API Key
}

// ä½¿ç”¨å·¥å‚åˆ›å»º Provider
factory := provider.NewMultiProviderFactory()
p, err := factory.Create(config)

// å‘é€æ¶ˆæ¯
messages := []types.Message{
	{Role: types.RoleUser, Content: "Hello!"},
}

response, err := p.Complete(ctx, messages, nil)
fmt.Println(response.Message.Content)
```

### 2. åˆ‡æ¢ Provider

åªéœ€ä¿®æ”¹ `Provider` å­—æ®µï¼Œä»£ç æ— éœ€æ”¹åŠ¨ï¼š

```go
// ä» OpenAI åˆ‡æ¢åˆ° Groq
config.Provider = "groq"
config.Model = "llama-3.3-70b-versatile"

// åˆ‡æ¢åˆ°æœ¬åœ° Ollama
config.Provider = "ollama"
config.Model = "llama3.2"
config.BaseURL = "http://localhost:11434/v1"
config.APIKey = "" // Ollama ä¸éœ€è¦ API Key
```

## åŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | OpenAI | Anthropic | Gemini | Groq | OpenRouter | Mistral | Ollama | DeepSeek | GLM | Doubao | Moonshot |
|------|--------|-----------|--------|------|------------|---------|--------|----------|-----|--------|----------|
| æµå¼è¾“å‡º | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| å·¥å…·è°ƒç”¨ | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| è§†è§‰è¾“å…¥ | âœ… | âœ… | âœ… | âŒ | âœ… | âœ… | âš ï¸ | âŒ | âš ï¸ | âš ï¸ | âŒ |
| éŸ³é¢‘è¾“å…¥ | âœ… | âŒ | âœ… | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ |
| è§†é¢‘è¾“å…¥ | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ |
| æ¨ç†æ¨¡å‹ | âœ… o1/o3 | âŒ | âœ… Thinking | âŒ | âœ… | âœ… | âŒ | âœ… R1 | âŒ | âŒ | âŒ |
| Prompt Cache | âœ… | âœ… | âœ… | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ |
| è¶…é•¿ä¸Šä¸‹æ–‡ | 128K | 200K | 1M-2M | 128K | - | 128K | 128K | 64K | 128K | 128K | 200K |
| æœ¬åœ°éƒ¨ç½² | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ |
| æ— éœ€ API Key | âŒ | âŒ | âŒ | âŒ | âŒ | âŒ | âœ… | âŒ | âŒ | âŒ | âŒ |

**å›¾ä¾‹**ï¼š
- âœ… å®Œå…¨æ”¯æŒ
- âš ï¸ éƒ¨åˆ†æ¨¡å‹æ”¯æŒ
- âŒ ä¸æ”¯æŒ

## ä½¿ç”¨åœºæ™¯æ¨è

### ğŸš€ è¿½æ±‚é€Ÿåº¦

**Groq** - ä¸šç•Œæœ€å¿«çš„æ¨ç†é€Ÿåº¦

```go
config := &types.ModelConfig{
	Provider: "groq",
	Model:    "llama-3.3-70b-versatile",
	APIKey:   "gsk-xxx",
}
```

**é€‚åˆ**ï¼šå®æ—¶å¯¹è¯ã€å®¢æœç³»ç»Ÿã€å¿«é€ŸåŸå‹

### ğŸ’° æˆæœ¬ä¼˜åŒ–

**Ollama** - æœ¬åœ°éƒ¨ç½²ï¼Œé›¶ API æˆæœ¬

```go
config := &types.ModelConfig{
	Provider: "ollama",
	Model:    "llama3.2",
	BaseURL:  "http://localhost:11434/v1",
}
```

**é€‚åˆ**ï¼šå¼€å‘æµ‹è¯•ã€ç¦»çº¿åº”ç”¨ã€éšç§æ•æ„Ÿ

### ğŸ¯ é€šç”¨åœºæ™¯

**OpenAI GPT-4o** - æ€§ä»·æ¯”æœ€é«˜

```go
config := &types.ModelConfig{
	Provider: "openai",
	Model:    "gpt-4o",
	APIKey:   "sk-xxx",
}
```

**é€‚åˆ**ï¼šå¤§å¤šæ•°åº”ç”¨åœºæ™¯

### ğŸ§  å¤æ‚æ¨ç†

**OpenAI o1-preview** æˆ– **DeepSeek R1**

```go
// OpenAI o1
config := &types.ModelConfig{
	Provider: "openai",
	Model:    "o1-preview",
	APIKey:   "sk-xxx",
}

// DeepSeek R1ï¼ˆæ›´ä¾¿å®œï¼‰
config := &types.ModelConfig{
	Provider: "deepseek",
	Model:    "deepseek-reasoner",
	APIKey:   "sk-xxx",
}
```

**é€‚åˆ**ï¼šæ•°å­¦é—®é¢˜ã€ä»£ç è°ƒè¯•ã€å¤æ‚è§„åˆ’

### ğŸ“š é•¿ä¸Šä¸‹æ–‡

**Gemini** - 1M-2M è¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆæœ€é•¿ï¼‰

```go
config := &types.ModelConfig{
	Provider: "gemini",
	Model:    "gemini-1.5-pro",    // 2M tokens
	// Model:    "gemini-2.0-flash-exp", // 1M tokens
	APIKey:   "your-key",
}
```

**é€‚åˆ**ï¼šå®Œæ•´ä»£ç ä»“åº“åˆ†æã€é•¿ç¯‡æ–‡æ¡£å¤„ç†ã€è§†é¢‘ç†è§£

**Moonshot Kimi** - 200K è¶…é•¿ä¸Šä¸‹æ–‡

```go
config := &types.ModelConfig{
	Provider: "moonshot",
	Model:    "moonshot-v1-128k", // æˆ– moonshot-v1-32k
	APIKey:   "sk-xxx",
}
```

**é€‚åˆ**ï¼šæ–‡æ¡£åˆ†æã€é•¿æ–‡æœ¬ç†è§£

### ğŸŒ æ¨¡å‹èšåˆ

**OpenRouter** - ä¸€æ¬¡æ¥å…¥ï¼Œæ•°ç™¾æ¨¡å‹

```go
config := &types.ModelConfig{
	Provider: "openrouter",
	Model:    "openai/gpt-4o",      // æˆ–ä»»ä½•æ”¯æŒçš„æ¨¡å‹
	APIKey:   "sk-or-xxx",
}

// éšæ—¶åˆ‡æ¢æ¨¡å‹ï¼Œæ— éœ€æ›´æ”¹ä»£ç 
config.Model = "anthropic/claude-3-opus"
config.Model = "google/gemini-pro"
config.Model = "meta-llama/llama-3-70b"
```

**é€‚åˆ**ï¼šéœ€è¦å¤šæ¨¡å‹æ”¯æŒã€æ¨¡å‹ A/B æµ‹è¯•

## ç¯å¢ƒå˜é‡é…ç½®

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡é…ç½® API Keysï¼š

```bash
# å›½é™… Providers
export OPENAI_API_KEY="sk-xxx"
export ANTHROPIC_API_KEY="sk-ant-xxx"
export GEMINI_API_KEY="your-key"
export GROQ_API_KEY="gsk-xxx"
export OPENROUTER_API_KEY="sk-or-xxx"
export MISTRAL_API_KEY="xxx"

# ä¸­å›½ Providers
export DEEPSEEK_API_KEY="sk-xxx"
export ZHIPU_API_KEY="xxx"
export DOUBAO_API_KEY="xxx"
export MOONSHOT_API_KEY="sk-xxx"

# Ollamaï¼ˆæœ¬åœ°éƒ¨ç½²ï¼Œå¯é€‰ï¼‰
export OLLAMA_BASE_URL="http://localhost:11434/v1"
```

ç„¶ååœ¨ä»£ç ä¸­ä½¿ç”¨ï¼š

```go
import "os"

config := &types.ModelConfig{
	Provider: "openai",
	Model:    "gpt-4o",
	APIKey:   os.Getenv("OPENAI_API_KEY"),
}
```

## ç»Ÿä¸€æ¥å£

æ‰€æœ‰ Provider éƒ½å®ç°ç›¸åŒçš„æ¥å£ï¼Œç¡®ä¿ä»£ç å…¼å®¹æ€§ï¼š

```go
type Provider interface {
	// æµå¼å¯¹è¯
	Stream(ctx context.Context, messages []Message, opts *StreamOptions) (<-chan StreamChunk, error)

	// éæµå¼å¯¹è¯
	Complete(ctx context.Context, messages []Message, opts *StreamOptions) (*CompleteResponse, error)

	// è·å–é…ç½®
	Config() *ModelConfig

	// è·å–èƒ½åŠ›
	Capabilities() ProviderCapabilities

	// è®¾ç½®/è·å–ç³»ç»Ÿæç¤ºè¯
	SetSystemPrompt(prompt string) error
	GetSystemPrompt() string

	// å…³é—­è¿æ¥
	Close() error
}
```

## æ¶æ„ä¼˜åŠ¿

### OpenAI å…¼å®¹å±‚

å¤§å¤šæ•° Provider åŸºäº OpenAI å…¼å®¹å±‚å®ç°ï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **å¿«é€Ÿå¼€å‘**ï¼šæ–°å¢ Provider åªéœ€ 50-100 è¡Œä»£ç 
2. **ç»Ÿä¸€ä½“éªŒ**ï¼šAPI è°ƒç”¨æ–¹å¼å®Œå…¨ä¸€è‡´
3. **è‡ªåŠ¨é‡è¯•**ï¼šå†…ç½® 429/5xx é”™è¯¯é‡è¯•æœºåˆ¶
4. **æµå¼ä¼˜åŒ–**ï¼šé«˜æ•ˆçš„ SSE æµå¼è§£æ
5. **å¤šæ¨¡æ€æ”¯æŒ**ï¼šç»Ÿä¸€çš„å›¾ç‰‡/éŸ³é¢‘å¤„ç†

### å¯æ‰©å±•æ€§

```go
// è½»æ¾æ·»åŠ æ–° Provider
type NewProvider struct {
	*OpenAICompatibleProvider
}

func NewNewProvider(config *types.ModelConfig) (Provider, error) {
	options := &OpenAICompatibleOptions{
		RequireAPIKey: true,
		DefaultModel:  "model-name",
	}

	return NewOpenAICompatibleProvider(config, "https://api.example.com/v1", "NewProvider", options)
}
```

## æ€§èƒ½ä¼˜åŒ–

### è¿æ¥å¤ç”¨

Provider å®ä¾‹ä¼šå¤ç”¨ HTTP è¿æ¥ï¼š

```go
// âœ… æ¨èï¼šå¤ç”¨ Provider å®ä¾‹
provider, _ := factory.Create(config)
for i := 0; i < 100; i++ {
	response, _ := provider.Complete(ctx, messages, nil)
}

// âŒ é¿å…ï¼šæ¯æ¬¡åˆ›å»ºæ–°å®ä¾‹
for i := 0; i < 100; i++ {
	provider, _ := factory.Create(config)
	response, _ := provider.Complete(ctx, messages, nil)
}
```

### å¹¶å‘è¯·æ±‚

```go
// å¹¶å‘å‘é€å¤šä¸ªè¯·æ±‚
var wg sync.WaitGroup
for i := 0; i < 10; i++ {
	wg.Add(1)
	go func(index int) {
		defer wg.Done()
		response, _ := provider.Complete(ctx, messages[index], nil)
		// å¤„ç†å“åº”
	}(i)
}
wg.Wait()
```

## æ•…éšœè½¬ç§»

```go
// ä¸» Provider + å¤‡ç”¨ Provider
primaryConfig := &types.ModelConfig{
	Provider: "openai",
	Model:    "gpt-4o",
	APIKey:   os.Getenv("OPENAI_API_KEY"),
}

fallbackConfig := &types.ModelConfig{
	Provider: "groq",
	Model:    "llama-3.3-70b-versatile",
	APIKey:   os.Getenv("GROQ_API_KEY"),
}

// å°è¯•ä¸» Provider
primaryProvider, _ := factory.Create(primaryConfig)
response, err := primaryProvider.Complete(ctx, messages, nil)

if err != nil {
	// å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨ Provider
	fallbackProvider, _ := factory.Create(fallbackConfig)
	response, err = fallbackProvider.Complete(ctx, messages, nil)
}
```

## ä¸‹ä¸€æ­¥

- æŸ¥çœ‹å…·ä½“ Provider çš„è¯¦ç»†æ–‡æ¡£
- äº†è§£ [Agent é›†æˆ](../core-concepts/agent.md)
- å­¦ä¹  [å·¥å…·è°ƒç”¨](../examples/tools/custom.md)
- æ¢ç´¢ [ä¸­é—´ä»¶](../core-concepts/middleware.md)

## ç›¸å…³èµ„æº

- [Provider æ¥å£å®šä¹‰](https://pkg.go.dev/github.com/wordflowlab/agentsdk/pkg/provider)
- [ç±»å‹å®šä¹‰](https://pkg.go.dev/github.com/wordflowlab/agentsdk/pkg/types)
- [GitHub ç¤ºä¾‹](https://github.com/wordflowlab/agentsdk/tree/main/examples)
